{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b234aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e493272e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class toy_Liner(nn.Module):\n",
    "    def __init__(self, in_features, out_features, bias=None, device=None, dtype=torch.float32):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.empty(out_features, in_features,dtype=dtype))\n",
    "        self.bias = nn.Parameter(torch.empty(out_features,dtype=dtype)) if bias else None\n",
    "        self.device = device\n",
    "        \n",
    "        self.set_weights()\n",
    "    \n",
    "    def set_weights(self,w=None):\n",
    "        if w == None:\n",
    "            nn.init.trunc_normal_(self.weight)\n",
    "        else:\n",
    "            self.weight.data = w\n",
    "    \n",
    "    def forward(self,x):\n",
    "        out = x @ self.weight.T\n",
    "        if self.bias != None:\n",
    "            out += self.bias\n",
    "        return out\n",
    "    \n",
    "\n",
    "class toy_Embedding(nn.Module):\n",
    "    def __init__(self, num_embd, embd_dim, device = None,dtype = torch.float32) -> None:\n",
    "        super().__init__()\n",
    "        self.embd = nn.Parameter(torch.empty(num_embd,embd_dim,dtype=dtype))\n",
    "        self.device = device\n",
    "\n",
    "        self.set_embd()\n",
    "        \n",
    "    def set_embd(self,embd=None):\n",
    "        if embd == None:\n",
    "            nn.init.trunc_normal_(self.embd)\n",
    "        else:\n",
    "            self.embd.data = embd \n",
    "    \n",
    "    def forward(self,x):\n",
    "        return self.embd[x]\n",
    "    \n",
    "class toy_RMSnorm(nn.Module):\n",
    "    def __init__(self, d_model, eps: float = 1e-5, device = None, dtype = torch.float32):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.eps = eps\n",
    "        self.gain = nn.Parameter(torch.empty(d_model,dtype=dtype))\n",
    "        self.device = device\n",
    "\n",
    "        self.set_para()\n",
    "        \n",
    "    def set_para(self,g=None):\n",
    "        if g==None:\n",
    "            nn.init.trunc_normal_(self.gain,1,0.02)\n",
    "        else:\n",
    "            self.gain.data = g\n",
    "    \n",
    "    def forward(self,x):\n",
    "        rmsx = x.square().mean(-1,keepdim=True) \n",
    "        out = x*self.gain/torch.sqrt(rmsx+self.eps)\n",
    "        return out \n",
    "        \n",
    "        \n",
    "class toy_SwiGLU(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, device=None, dtype=torch.float32):\n",
    "        super().__init__()\n",
    "        self.W1 = nn.Parameter(torch.empty(d_ff,d_model,dtype=dtype))\n",
    "        self.W2 = nn.Parameter(torch.empty(d_model,d_ff,dtype=dtype))\n",
    "        self.W3 = nn.Parameter(torch.empty(d_ff,d_model,dtype=dtype))\n",
    "        self.device = device\n",
    "    \n",
    "        self.set_para()\n",
    "    def set_para(self,w1=None,w2=None,w3=None):\n",
    "        if w1 == None:\n",
    "            nn.init.trunc_normal_(self.W1)\n",
    "        else:\n",
    "            self.W1.data = w1\n",
    "        if w2 == None:\n",
    "            nn.init.trunc_normal_(self.W2)\n",
    "        else:\n",
    "            self.W2.data = w2\n",
    "        if w3 == None:\n",
    "            nn.init.trunc_normal_(self.W3)\n",
    "        else:\n",
    "            self.W3.data = w3\n",
    "    \n",
    "    def forward(self,x):\n",
    "        W3x = x @ self.W3.T\n",
    "        W1x = x @ self.W1.T\n",
    "        Slu = W1x * torch.sigmoid(W1x)\n",
    "        return (Slu * W3x)@self.W2.T\n",
    "        \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3eac269",
   "metadata": {},
   "outputs": [],
   "source": [
    "class toy_RoPE(nn.Module):\n",
    "    def __init__(self, d_k, theta, max_len, device = None, dtype = torch.float32):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.rot_d = d_k//2\n",
    "        i = torch.arange(self.rot_d, device=device, dtype=dtype)         \n",
    "        j = torch.arange(max_len, device=device, dtype=dtype)      \n",
    "\n",
    "        inv_freq = torch.exp(-(2*i)/d_k * torch.log(torch.tensor(theta, device=device, dtype=dtype)))                   \n",
    "        thetas = j[:, None] * inv_freq[None, :]  \n",
    "        \n",
    "        cos_table = torch.cos(thetas)  #cos_table [token posistion, feature posistion]\n",
    "        sin_table = torch.sin(thetas)\n",
    "        \n",
    "        self.register_buffer(\"cos_table\",cos_table,persistent=False)\n",
    "        self.register_buffer(\"sin_table\",sin_table,persistent=False)\n",
    "    \n",
    "    def forward(self,x,tk_posistions):\n",
    "        cos = self.cos_table[tk_posistions] #(T,d/2)\n",
    "        sin = self.sin_table[tk_posistions] #(T,d/2)\n",
    "        x_rot = x[..., :2*self.rot_d]\n",
    "        x_pass = x[..., 2*self.rot_d:]\n",
    "        x1 = x_rot[...,0::2] #(T,d/2 + 1) ?\n",
    "        x2 = x_rot[...,1::2]\n",
    "        y1 = x1 * cos - x2 * sin\n",
    "        y2 = x1 * sin + x2 * cos\n",
    "        y_rot = torch.stack([y1, y2], dim=-1).flatten(-2)\n",
    "        return torch.cat([y_rot, x_pass], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fc35221c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3000, 0.9000, 1.8000],\n",
       "        [0.0577, 0.3462, 1.0385]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a  = torch.tensor([[1,2,3],[1,4,9]],dtype=torch.float32)\n",
    "g = torch.tensor([2,3,4],dtype=torch.float32)\n",
    "b = a.square().mean(-1,keepdim=True) + 2\n",
    "a*g/b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6441bba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8f24c07b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[48]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m theta = \u001b[32m0.1\u001b[39m\n\u001b[32m      4\u001b[39m max_d = d_k//\u001b[32m2\u001b[39m * \u001b[32m2\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m thetas = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m-\u001b[49m\u001b[43mi\u001b[49m\u001b[43m/\u001b[49m\u001b[43mmax_d\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43md_k\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m*\u001b[49m\u001b[43mj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmax_len\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mValueError\u001b[39m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "d_k = 10\n",
    "max_len = 5\n",
    "theta = 0.1\n",
    "max_d = d_k//2 * 2\n",
    "thetas = torch.tensor([torch.pow(theta,torch.tensor([-i/max_d for i in range(d_k)]))*j for j in range(max_len)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1b08e57c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.2589, 1.5849, 1.9953, 2.5119, 3.1623, 3.9811, 5.0119, 6.3096,\n",
       "        7.9433])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thetas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs336-basics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
